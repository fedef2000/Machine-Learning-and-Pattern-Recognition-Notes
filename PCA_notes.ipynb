{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)\n",
    "Principal Component Analysis (PCA) is an **unsupervised** technique for reducing the dimensionality of data while preserving as much information as possible.\n",
    "It is based on the covariance matrix and its eigenvectors.\n",
    "\n",
    "Steps of PCA:\n",
    "1. Compute the covariance matrix\n",
    "2. Obtain eigenvalues and eigenvectors\n",
    "3. Sort eigenvectors by decreasing eigenvalues\n",
    "4. Transform the data\n",
    "\n",
    "Given a N dimensions dataset, first we compute the covariance matrix. This can gives us information on the correlations between each dimension. \n",
    "\n",
    "Then we compute the eigenvalues and the corresponding eigenvectors. We order from highest to lowest eigenvalue. We can then build a matrix putting the eigenvectors as columns. This matrix is the one that we can use to perform the projection and thus reduce the dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, numpy, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance\n",
    "The covariance between two variables measures how they change together. If two variables increase or decrease together, they have positive covariance. If one increases while the other decreases, they have negative covariance. A covariance of zero means they are uncorrelated.\n",
    "\n",
    "If we have a dataset with n observations, each one woth two features: X and Y, the sample covariance is:\n",
    "\n",
    "$$\\text{Cov}(X, Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\mu_X) (Y_i - \\mu_Y)$$\n",
    "\n",
    "Where μ are the sample means of X and Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: we have 5 point in 2 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a simple dataset with 5 points in 2D\n",
    "v1 = numpy.array([[0, 3], [1, 5], [2, 8], [3, 10], [4, 12]])\n",
    "v2 = numpy.array([[0, 3], [0, 5], [0, 8], [0, 10], [0, 12]])\n",
    "\n",
    "# Compute mean\n",
    "v1_mean = numpy.mean(v1, axis=0)\n",
    "v2_mean = numpy.mean(v2, axis=0)\n",
    "\n",
    "sum = 0\n",
    "for v in v1:\n",
    "    sum += (v[0] - v1_mean[0]) * (v[1] - v1_mean[1])\n",
    "sum2=0\n",
    "for v in v2:\n",
    "    sum2 += (v[0] - v2_mean[0]) * (v[1] - v2_mean[1])\n",
    "\n",
    "cov = sum/len(v1)\n",
    "#cov2 = sum2/len(v2)\n",
    "\n",
    "cov\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance matrix\n",
    "PCA uses the covariance matrix because it provides useful information about the relationships between different dimensions. Specifically, it helps identify which dimensions are highly correlated (thus we can keep only one of them) and which dimensions are less correlated (so they capture distinct information).\n",
    "\n",
    "The covariance matrix captures relationships between variables:\n",
    "\t•\tHigh covariance → Strong linear relationship between two variables.\n",
    "\t•\tLow or zero covariance → Weak or no linear relationship.\n",
    "\n",
    "Given a dataset where each data is: \n",
    "$$\\bar{X} = (X_1, X_2, …, X_n)$$\n",
    "\n",
    "This is the formula of covariance matrix:\n",
    "$$\\Sigma =\n",
    "\\begin{bmatrix}\n",
    "\\text{Var}(X_1) & \\text{Cov}(X_1, X_2) & \\dots & \\text{Cov}(X_1, X_n) \\\\\n",
    "\\text{Cov}(X_2, X_1) & \\text{Var}(X_2) & \\dots & \\text{Cov}(X_2, X_n) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\text{Cov}(X_n, X_1) & \\text{Cov}(X_n, X_2) & \\dots & \\text{Var}(X_n)\n",
    "\\end{bmatrix}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
